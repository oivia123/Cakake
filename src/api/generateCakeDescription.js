import { buildPrompt } from "../utils/buildPrompt";

export async function generateCakeDescription({ tarotCards, allergies, inventory }) {
  const prompt = buildPrompt(
    tarotCards,
    allergies,
    inventory.missingIngredients,
    inventory.availableCakes
  );

  const response = await fetch("https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${process.env.REACT_APP_HF_API_TOKEN}`,
      "Content-Type": "application/json"
    },
    body: JSON.stringify({ inputs: prompt })
  });

  const data = await response.json();
  const fullOutput = data[0]?.generated_text || "AI æ¨¡å‹æœªè¿”å›ç»“æœã€‚";

  // ä»â€œ---â€ä¹‹åå¼€å§‹æˆªå–ç”Ÿæˆå†…å®¹
  const parts = fullOutput.split('---');
  const modelOutput = parts.length > 1 ? parts[parts.length - 1].trim() : fullOutput.trim();

  // æ¸…é™¤æ¨¡å‹è¯¯åŠ çš„ "- Cake Name" è¡Œï¼ˆå¦‚æœå®ƒä»ç„¶æ²¡å¬è¯ï¼‰
  const filtered = modelOutput
    .split('\n')
    .filter(line => !line.match(/^-\s.*Cake$/)) // è¿‡æ»¤å½¢å¦‚ "- Mocha Macadamia Tart" çš„è¡Œ
    .join('\n')
    .trim();

  console.log('ğŸ§ Cleaned LLM output:', filtered);
  return filtered;
}